{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07.Model_subclassing.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNk7xmqghfl4IGu7RhSWWD1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soohyunme/TensorFlow_Tutorial/blob/main/Code/07_Model_subclassing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceIx3RIefF2y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Device setting"
      ],
      "metadata": {
        "id": "lVyhR0vbEpVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0],True)"
      ],
      "metadata": {
        "id": "IZFQhWJFEZUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "HdWMPOUeEuUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train), (x_test,y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "WPt3ivEaEdB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalize"
      ],
      "metadata": {
        "id": "48Xn-xHFE6vw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(-1, 28, 28,1 ).astype('float32') / 255.0\n",
        "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0"
      ],
      "metadata": {
        "id": "hLEeGCNlXKRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "NhkrLuxLoJsx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN -> BatchNorm -> ReLU (Common structure)\n",
        "x 10"
      ],
      "metadata": {
        "id": "vdsNbwGaoLEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNBlock(layers.Layer):\n",
        "  def __init__(self, out_channels, kernel_size=3):\n",
        "    super(CNNBlock, self).__init__()\n",
        "    self.conv = layers.Conv2D(out_channels, kernel_size, padding='same')\n",
        "    self.bn = layers.BatchNormalization()\n",
        "\n",
        "  def call(self, input_tensor, training=False):\n",
        "    x = self.conv(input_tensor)\n",
        "    x = self.bn(x, training=training)\n",
        "    x = tf.nn.relu(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "DkK65zYCoEtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResBlock(layers.Layer):\n",
        "  def __init__(self, channels):\n",
        "    super(ResBlock, self).__init__()\n",
        "    self.cnn1 = CNNBlock(channels[0])\n",
        "    self.cnn2 = CNNBlock(channels[1])\n",
        "    self.cnn3 = CNNBlock(channels[2])\n",
        "    self.pooling = layers.MaxPooling2D()\n",
        "    self.identity_mapping = layers.Conv2D(channels[1], 1, padding='same')\n",
        "\n",
        "  def call(self, input_tensor, training=False):\n",
        "    x = self.cnn1(input_tensor, training=training)\n",
        "    x = self.cnn2(x, training=training)\n",
        "    x = self.cnn3(\n",
        "        x + self.identity_mapping(input_tensor), training=training\n",
        "        )\n",
        "    return x"
      ],
      "metadata": {
        "id": "AlhQkvOGH1Fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet_Like(keras.Model):\n",
        "  def __init__(self, num_classes=10):\n",
        "    super(ResNet_Like, self).__init__()\n",
        "    self.block1 = ResBlock([32, 32, 64])\n",
        "    self.block2 = ResBlock([128, 128, 256])\n",
        "    self.block3 = ResBlock([128, 256, 512])\n",
        "    self.pool = layers.GlobalAveragePooling2D()\n",
        "    self.classifier = layers.Dense(num_classes)\n",
        "\n",
        "  def call(self, input_tensor, training=False):\n",
        "    x = self.block1(input_tensor, training=training)\n",
        "    x = self.block2(x, training=training)\n",
        "    x = self.block3(x, training=training)\n",
        "    x = self.pool(x)\n",
        "    return self.classifier(x)\n",
        "  \n",
        "  def model(self):\n",
        "    x = keras.Input(shape=(28, 28, 1))\n",
        "    return keras.Model(inputs=[x], outputs=self.call(x))"
      ],
      "metadata": {
        "id": "-qUuEqfHM7CP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet_Like(num_classes=10)\n",
        "model.compile(\n",
        "    optimizer = keras.optimizers.Adam(),\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=1, verbose=2)\n",
        "print(model.summary())\n",
        "print(model.model().summary())\n",
        "model.evaluate(x_test, y_test, batch_size=64, verbose=2)\n"
      ],
      "metadata": {
        "id": "pAOLiEfOo-hR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}